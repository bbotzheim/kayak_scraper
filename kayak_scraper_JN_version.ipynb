{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\bdbot\\\\Documents'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import csv\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.rei.com/search?q=kayak\")\n",
    "#show all results\n",
    "all_results_button = driver.find_element_by_xpath('//*[@id=\"app-main\"]/div/div/div[1]/div/div[2]/div[2]/div[2]/div/ul/li[last()]')\n",
    "all_results_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_products = WebDriverWait(driver, 10)\n",
    "products = wait_products.until(EC.presence_of_all_elements_located((By.XPATH, '//*[@id=\"search-results\"]/ul/li')))\n",
    "\n",
    "# create and open two csv files\n",
    "products_csv = open('products.csv', 'w', encoding='utf-8', newline='')\n",
    "reviews_csv = open('reviews.csv', 'w', encoding='utf-8', newline='')\n",
    "product_writer = csv.writer(products_csv)\n",
    "reviews_writer = csv.writer(reviews_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin scraping product 1\n",
      "Finished scraping product 1\n",
      "Begin scraping product 2\n",
      "Finished scraping product 2\n",
      "Begin scraping product 3\n",
      "Finished scraping product 3\n",
      "Begin scraping product 4\n",
      "Finished scraping product 4\n",
      "Begin scraping product 5\n",
      "Finished scraping product 5\n",
      "Begin scraping product 6\n",
      "Finished scraping product 6\n",
      "Begin scraping product 7\n",
      "Finished scraping product 7\n",
      "Begin scraping product 8\n",
      "Finished scraping product 8\n",
      "Begin scraping product 9\n",
      "Finished scraping product 9\n",
      "Begin scraping product 10\n",
      "Finished scraping product 10\n",
      "Begin scraping product 11\n",
      "Message: \n",
      "\n",
      "Unscraped REI Outlet page?\n",
      "Begin scraping product 12\n",
      "Finished scraping product 12\n",
      "Begin scraping product 13\n",
      "Finished scraping product 13\n",
      "Begin scraping product 14\n",
      "Finished scraping product 14\n",
      "Begin scraping product 15\n",
      "Finished scraping product 15\n",
      "Begin scraping product 16\n",
      "Finished scraping product 16\n",
      "Begin scraping product 17\n",
      "Finished scraping product 17\n",
      "Begin scraping product 18\n",
      "Finished scraping product 18\n",
      "Begin scraping product 19\n",
      "Finished scraping product 19\n",
      "Begin scraping product 20\n",
      "Finished scraping product 20\n",
      "Begin scraping product 21\n",
      "Finished scraping product 21\n",
      "Begin scraping product 22\n",
      "Finished scraping product 22\n",
      "Begin scraping product 23\n",
      "Finished scraping product 23\n",
      "Begin scraping product 24\n",
      "Finished scraping product 24\n",
      "Begin scraping product 25\n",
      "Finished scraping product 25\n",
      "Begin scraping product 26\n",
      "Finished scraping product 26\n",
      "Begin scraping product 27\n",
      "Finished scraping product 27\n",
      "Begin scraping product 28\n",
      "Finished scraping product 28\n",
      "Begin scraping product 29\n",
      "Finished scraping product 29\n",
      "Begin scraping product 30\n",
      "Finished scraping product 30\n",
      "Begin scraping product 31\n",
      "Finished scraping product 31\n",
      "Begin scraping product 32\n",
      "Finished scraping product 32\n",
      "Begin scraping product 33\n",
      "Finished scraping product 33\n",
      "Begin scraping product 34\n",
      "Finished scraping product 34\n",
      "Begin scraping product 35\n",
      "Finished scraping product 35\n",
      "Begin scraping product 36\n",
      "Finished scraping product 36\n",
      "Begin scraping product 37\n",
      "Finished scraping product 37\n",
      "Begin scraping product 38\n",
      "Finished scraping product 38\n",
      "Begin scraping product 39\n",
      "Finished scraping product 39\n",
      "Begin scraping product 40\n",
      "Finished scraping product 40\n",
      "Begin scraping product 41\n",
      "Finished scraping product 41\n",
      "Begin scraping product 42\n",
      "Finished scraping product 42\n",
      "Begin scraping product 43\n",
      "Finished scraping product 43\n",
      "Begin scraping product 44\n",
      "Finished scraping product 44\n",
      "Begin scraping product 45\n",
      "Finished scraping product 45\n",
      "Begin scraping product 46\n",
      "Finished scraping product 46\n",
      "Begin scraping product 47\n",
      "Finished scraping product 47\n",
      "Begin scraping product 48\n",
      "Finished scraping product 48\n",
      "Begin scraping product 49\n",
      "Finished scraping product 49\n",
      "Begin scraping product 50\n",
      "Finished scraping product 50\n",
      "Begin scraping product 51\n",
      "Finished scraping product 51\n",
      "Begin scraping product 52\n",
      "Finished scraping product 52\n",
      "Begin scraping product 53\n",
      "Finished scraping product 53\n",
      "Begin scraping product 54\n",
      "Finished scraping product 54\n",
      "Begin scraping product 55\n",
      "Finished scraping product 55\n",
      "Begin scraping product 56\n",
      "Finished scraping product 56\n",
      "Begin scraping product 57\n",
      "Finished scraping product 57\n",
      "Begin scraping product 58\n",
      "Finished scraping product 58\n",
      "Begin scraping product 59\n",
      "Finished scraping product 59\n",
      "Begin scraping product 60\n",
      "Finished scraping product 60\n",
      "Begin scraping product 61\n",
      "Finished scraping product 61\n",
      "Begin scraping product 62\n",
      "Finished scraping product 62\n",
      "Begin scraping product 63\n",
      "Finished scraping product 63\n",
      "Begin scraping product 64\n",
      "Finished scraping product 64\n",
      "Begin scraping product 65\n",
      "Finished scraping product 65\n",
      "Begin scraping product 66\n",
      "Finished scraping product 66\n",
      "Begin scraping product 67\n",
      "Message: \n",
      "\n",
      "Unscraped REI Outlet page?\n",
      "Begin scraping product 68\n",
      "Message: \n",
      "\n",
      "Unscraped REI Outlet page?\n",
      "Begin scraping product 69\n",
      "Message: \n",
      "\n",
      "Unscraped REI Outlet page?\n",
      "Begin scraping product 70\n",
      "Message: \n",
      "\n",
      "Unscraped REI Outlet page?\n",
      "Begin scraping product 71\n",
      "Finished scraping product 71\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,len(products)+1):\n",
    "    #each loop will choose the next product in the list\n",
    "    button = driver.find_element_by_xpath('//*[@id=\"search-results\"]/ul/li[{x}]/a'.format(x=i))\n",
    "    button.click()\n",
    "    \n",
    "    #exceptions should only happen when a product redirects to REI Outlet (which has a different layout and since about 5 \n",
    "    #products link to it was not deemed necessary to scrape)\n",
    "    try:\n",
    "        print('Begin scraping product {x}'.format(x = i))\n",
    "\n",
    "        wait_name = WebDriverWait(driver, 10)\n",
    "        name = wait_name.until(EC.presence_of_all_elements_located((By.XPATH,'//div[@class=\"product-title\"]')))[0].text\n",
    "        product_id = driver.find_element_by_xpath('//*[@id=\"product-container\"]/div[2]/div/div[2]/div[3]/div[2]/span/span').text\n",
    "        \n",
    "        #products with 0 reviews and  0 ratings cause error\n",
    "        try:\n",
    "            total_reviews = driver.find_element_by_xpath('//*[@id=\"bv-rating-summary\"]/div/div/div[3]/button').text\n",
    "            total_reviews = \"\".join((re.findall(\"[0-9]\", total_reviews)))\n",
    "            rating = driver.find_element_by_xpath('//*[@id=\"bv-rating-summary\"]/div/div/div[2]/button').text\n",
    "        except:\n",
    "            total_reviews = 0\n",
    "            rating = 0\n",
    "        \n",
    "        #a few prices have a range and require further selection\n",
    "        try:\n",
    "            price = driver.find_element_by_xpath('//*[@id=\"js-product-information-price\"]/div/span/span/span').text\n",
    "        except:\n",
    "            price = driver.find_element_by_xpath('//*[@id=\"js-product-information-price\"]/div/span/div/span/span[1]').text\n",
    "        \n",
    "        #change price to float\n",
    "        price = float(re.sub('[$,/,]', '', price))\n",
    "        #create dictionary\n",
    "        product_dict = {'product_id': product_id, 'name':name, 'total_reviews':total_reviews, 'rating': rating, 'price': price}\n",
    "        \n",
    "        #locate product details and split by names and values. Since different product pages don't all have the same \n",
    "        #technical details, a temporary dictionary is used to draw from. If the page is missing the value, 'None' is used\n",
    "        #instead\n",
    "        tech_specs = driver.find_element_by_xpath('//*[@id=\"product-wrapper\"]/div[9]/div[1]/div[2]/div/table/tbody')\n",
    "        spec_names = tech_specs.find_elements_by_tag_name('th')\n",
    "        spec_values = tech_specs.find_elements_by_tag_name('td')\n",
    "\n",
    "        temp = {}\n",
    "        c = iter(spec_values)\n",
    "        for name in spec_names:\n",
    "            temp[name.text] = (next(c).text)\n",
    "\n",
    "        product_dict['Best Use'] = temp.get('Best Use', None)\n",
    "        product_dict['Material(s)'] = temp.get('Material(s)', None)\n",
    "        product_dict['Length'] = temp.get('Length', None)\n",
    "        product_dict['Width'] = temp.get('Width', None)\n",
    "        product_dict['Depth'] = temp.get('Depth', None)\n",
    "        product_dict['Weight'] = temp.get('Weight', None)\n",
    "        product_dict['Cockpit Size'] = temp.get('Cockpit Size', None)\n",
    "        product_dict['Seat Type'] = temp.get('Seat Type', None)\n",
    "        product_dict['Number of Paddlers'] = temp.get('Number of Paddlers', None)\n",
    "        product_dict['Hatch Capacity'] = temp.get('Hatch Capacity', None)\n",
    "        product_dict['Weight Capacity (lbs)'] = temp.get('Weight Capacity (lbs)', None)\n",
    "        product_dict['Tracking System'] = temp.get('Tracking System', None)\n",
    "        product_dict['Foldable'] = temp.get('Foldable', None)\n",
    "        product_dict['Packed Dimensions'] = temp.get('Packed Dimensions', None)\n",
    "        product_dict['Sustainability'] = temp.get('Sustainability', None)\n",
    "        \n",
    "        #write complete product dictionary as a new row in csv\n",
    "        product_writer.writerow(product_dict.values())\n",
    "        \n",
    "        \n",
    "        ##scrape from reviews. If no reviews exists, add no reviews to dictionary and move on.\n",
    "        #Reviews are maxed at 8. We used a try/except method to determine if a 'load more' button\n",
    "        #exists and if it does, click it until we cannot locate it anymore (all reviews should be visible).\n",
    "        reviews_dict = {'Product ID':product_id}\n",
    "        \n",
    "        if int(total_reviews) >= 1:\n",
    "            try:\n",
    "                load_more = driver.find_element_by_xpath('//*[@id=\"BVRRContainer\"]/div/div/div/div/div[3]/div/button/span')\n",
    "                load_more_exists = True\n",
    "            except:\n",
    "                load_more_exists = False\n",
    "            while load_more_exists:\n",
    "                try:\n",
    "                    load_more.click()\n",
    "                except:\n",
    "                    load_more_exists = False\n",
    "            \n",
    "            #Now that all reviews are visible, locate all reviews.\n",
    "            reviews = driver.find_elements_by_xpath('//*[@id=\"BVRRContainer\"]/div/div/div/div/ol/li')\n",
    "            #Loop through reviews and add each body text to dictionary\n",
    "            index = 1\n",
    "            for review in reviews:\n",
    "                body = review.find_element_by_class_name('bv-content-summary-body-text').text\n",
    "                reviews_dict['review {x}'.format(x = index)] = body\n",
    "                index += 1\n",
    "        else:\n",
    "            reviews_dict['Reviews'] = 'No reviews'\n",
    "        \n",
    "        #write complete dictionary as a new row in csv\n",
    "        reviews_writer.writerow(reviews_dict.values())\n",
    "        \n",
    "        #sleeping time before returning to results page\n",
    "        print('Finished scraping product {x}'.format(x = i))\n",
    "        time.sleep(5)\n",
    "        driver.back()\n",
    "        time.sleep(2)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Unscraped REI Outlet page?\")\n",
    "        time.sleep(3)\n",
    "        driver.back()\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#close csv files\n",
    "products_csv.close()\n",
    "reviews_csv.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
